\chapter{Selbstüberwachtes Lernen}
\label{chap:selfsupervised}
\qq{Warum besteht interesse an unsupervised/selfsupervised Lernen?}
Ein Teil des Erfolges von CNNs ist auf die Verfügbarkeit von großen annotierten Datensätzen wie ImageNet zurückzuführen
\autocite{SunRevisitingUnreasonableEffectiveness2017}.
Jedoch ist die Anzahl der Bilder im ImageNet-Datensatz in den vergangen Jahren gleich geblieben, während die  verfügbare Netzwerkkapazität und GPU-Rechenleistung angestiegen ist.
\citeauthor{SunRevisitingUnreasonableEffectiveness2017} zeigen mithilfe des JFT-300M-Datensets (300 Millionen annotierte Bilder), dass die Performanz von allen getesteten Aufgaben (Klassifizerung, Segmentierung, etc.)
logaritmisch zur Datenmenge ansteigt. 

Für einen linearen Performanzanstieg bräuchte man exponetiell mehr Daten.
Die Annotierung von Datensets ist immer ein teuerer Prozess \autocite[988]{ValvenyDatasetsAnnotationsDocument2014}.
Die manuelle Annotation einer Dokumentenseite kann mehr als eine Stunde in Anspruch nehmen. 

% Das kollaborative Annotieren von Datensets ermöglicht es große Datenmengen in hoher Qualität zu annotieren.
% Das reCAPTCHA-Projekt \cite{reCAPTCHA} h  
% semiautomatisch



\begin{figure}[htbp!]
    \centering
    \caption{Schematische Darstellung von ML-Methoden}
    \label{fig:all}
    \subfloat[Neuronales Netzwerke und Training \cite{CholletDeeplearningPython2018}\label{fig:sub1}]{    
      \includegraphics[width=0.3\textwidth, valign=t]{figures/graphs/chollet2018supervised.pdf}
      \vphantom{\includegraphics[width=0.3\textwidth,valign=t]{figures/graphs/selfsupervised.pdf}}
    }
    \subfloat[Autoencoder\label{fig:sub2}]{    
      \includegraphics[width=0.3\textwidth, valign=t]{figures/graphs/autoencoder.pdf}
      \vphantom{\includegraphics[width=0.3\textwidth,valign=t]{figures/graphs/selfsupervised.pdf}}
    }
    \subfloat[Selbstüberwachtes Lernen\label{fig:sub3}]{    
      \includegraphics[width=0.3\textwidth, valign=t]{figures/graphs/selfsupervised.pdf}
    }
    
    
\end{figure}
\vspace{0.5cm}



\section{Unüberwachtes Lernen von unterscheidbaren Features}

\sfigure{Workflow}{figures/graphs/dosovitskiy2015_workflow.pdf}

Jigsaw
\cite{NorooziUnsupervisedLearningVisual2016}
% \begin{figure}
%     \includegraphics[]{figures/graphs/exp.pdf} 
%     \caption{Image}
%   \end{figure}

\cite{DosovitskiyDiscriminativeUnsupervisedFeature2016} Loss-Funktion skaliert nicht auf viele Klassen.
Letzter Klassifiezierungslayer ist Fully-Connected. Je mehr Image-Patches desto mehr Parameter.

\cite{DoerschMultitaskSelfSupervisedVisual2017} benutzt Triplet-Loss.
Der Verlust wird mit einem Positiv und einem Negativbeispiel berechnet.
Die Idee dafür kommt von \citeauthor{WangUnsupervisedLearningVisual2015}.
Die Kosinus-Ähnlichkeit misst den Winkel zwischen zwei Vektoren. Vektoren mit einem Winkel von 0 haben
eine Kosinus-Maß von 1. Der größtmögliche Winkel hat eine Kosinusmaß von 0.
